{
  "hash": "524331301aefb5b05499c0b9067981a6",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Discussion on Methods to Identify Institutional Investors from Messy Data\nauthor:\n  - name: Nicholas Polimeni\n    affiliation:\n      - name: 'Urban Research Group, Georgia Institute of Technology'\n        city: Atlanta\n        state: GA\ndate: '2024-04-12'\ncategories:\n  - code\n  - analysis\nexecute:\n  echo: false\nformat:\n  html:\n    embed-resources: true\n    self-contained: true\n    toc: true\nnotebook-links: false\n---\n\n## Introduction\n\nThis is a written version of a presentation I gave to a working group of researchers studying the impact of institutional investors. The session was organized by Anthony Damiano, PhD and hosted by the Center for Urban and Regional Affairs at the University of Minnesota Twin Cities.\n\nA need for accessible and robust methods to identify insitutional investors, especially single-family rental (SFR) investors, motivates this discussion. Considering the lack of rental registries in the United States, researchers must bear significant technical burdens in identifying these investors from messy parcel and sales records. The challenges include, but are not limited to: inconsistent naming, corporations with multiple different business addresses, and difficulty in acquiring data, especially historical data.\n\n::: {.callout-note}\nI refer to algorithms that identify insitutional investors as entity resolution or clustering algorithms, depending on which I am referring to. I use these terms to reflect the general desire to group same-owners (such as subsidary corporations) together within data, even if the exact definition of these algorithms differ. Classification algorithms may also be relevant, but we generally don't have a complete list of investors to supervise learning. I discuss machine learning (clustering, classification, and deep learning) algorithms in more detail later.\n:::\n\n::: {.callout-tip title=\"Session Recording Link\"}\nWill add after session\n:::\n\n## Tradeoffs\n\nUnfortunately, given data challenges, all methods must make a trade off between accuracy, runtime, and technical complexity.\n\n### Accuracy\n\nFor accuracy, we can prioritize absolute number of matches, percent correct matches, percent true-matches vs false-matches, or some combination of these criteria.\n\nGenerally, most situations aim to maximize the number of correct matches without crossing a threshold for percent false-matches.\n\nWhile accuracy is most important, it is ideal to have a precise algorithm that is invariant to minor changes in data format. Some data may contain, for instance, street postfix abbreviations (e.g. \"STREET\" or \"ST\") within owner address whereas others will not. An ideal algorithm should retain its accuracy and precision regardless of these differences.\n\n### Runtime (Time Complexity)\n\nFor execution time or runtime, needs vary. For practioniers, waiting days for an algorithm to run is not feasible. Researchers are generally more willing to use these algorithms. We must also consider the hardware each party has access to.\n\nThere are three target categories:\n1. Good algorithms that can be run quickly and easily on any hardware,\n2. Better algorithms that experienced professionals can run if necessary,\n3. Optimal algorithms that may require offsite, vast infrasture.\n\nIt is unlikely that the marginal improvements from categeory 2 to 3 is worth the additional effort. ALthough, training a deep-learning model might be an exception, as it only requires extensive infrastructure once. We will discuss this further later.\n\n\n### Technical and Implementation Complexity\nTechnical complexity is related to algorithmic effieciency; however, some fast algorithms might be very difficult to implement. For instance, concurrent processing.\n\n---\n\n## Time Complexity\nLet's go slightly more in depth regarding algorithm efficiency, otherwise known as time and space complexity.\n\nWe are generally more concerned with time complexity. It is relatively cheap to buy more RAM... but, the last I checked, no one has managed to buy time yet.\n\nWe can categorize algorithms with Big-O notation, with the time complexity is written as O(f(n)), where f(n) is a function that is an upper bound for the runtime of the algorithm given input of size n.\n\nWhen we say runtime, we don't mean how long it takes to run on my computer or your computer, rather the number of operations in the worst case. We also don't care much about how long these algorithms take to run on very small problems, only as the problems get larger.\n \nTODO: site\n\n---\n\n## Time Complexity of Single Comparisons\n\n### Vectorized Comparison (Equals Operator): `O(1)`\n\nExample\n\nBoth `\"A\" =? \"A\"` and `\"1 MAIN ST\" =? \"1 MAIN ST\"` take approximately the same time to execute, despite longer strings in the second group. This a result of the digital design within a processor.\n\n### Similiarity Metrics or other Iterative Comparison: `O(n)`\n\nExample\n\nRunning Levenshtein Distance, a common string distance metric, on `\"A\" =? \"A\"` and `\"1 MAIN ST\" =? \"1 MAIN ST\"` takes 1 and 9 operations to execute, respectively.\n\n## Time Complexity of Entity Resolution Algorithms\n\nNote: these are estimates. Don't cite them.\n\nTODO: add examples, add sources\n\n\n### Aggreggate / GroupBy: `O(n)`\n\nExample (Python Pandas)\n\ncan probably just use code\n\n`data.groupby(\"owner_address\")`\n\n### Similarity Threshold Grouping: `O(n^2)`\n\nExample\n\ncan probably just use code\n\nNote: Clustering function in (OpenRefine). Please refer to Dr. Brian An's work (site).\nNote: can be improved with blocking; Token-based (n-gram, key collision, etc.)\nCharacter-based, also known as Edit distance (Levenshtein distance, PPM, etc.)\n\n## Time Complexity of Machine Learning Algorithms\n\n### K-Nearest Neighbors (Clustering, Unsupervised): `O(n^2)`\n\n\n### Approximate K-Nearest Neighbors (Clustering, Unsupervised): generally at or below `O(n)`\n- FAISS\n- Metric Trees\n- Locality-Sensitive Hashing (LSH)\n- Hierarchical Navigable Small World (HNSW)\n\n### Deep Learning (Classification, Supervised): `O(n^n)`*\n\n\n## Approaches\n\n- Uncovering Paper (ADDR KEY)\n- Query method\n- More advanced ADDR KEY with letters + add BR (automate query step)\n- Custom Similiarity Functions\n- Comparing all methods\n- Optimized coding tools\n\n## Proposal: Methods Paper to Establish a More Definitive Answer\n\n## Conclusion\nUntil rental\n\n## Questions and Answers from the Live Session\nWill be recorded here after the conclusion of the session.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}