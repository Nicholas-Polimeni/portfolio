[
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Posts",
    "section": "",
    "text": "Discussion on Methods to Identify Institutional Investors from Messy Data\n\n\n\n\n\n\nwhitepaper\n\n\npresentation\n\n\n\n\n\n\n\n\n\nApr 12, 2024\n\n\nNicholas Polimeni\n\n\n\n\n\n\n\n\n\n\n\n\nGeospatial Analysis of Fulton County Tax Appeal Filings from 2011 to 2022\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nJan 22, 2024\n\n\nNicholas Polimeni\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/fulton-appeals/index.html",
    "href": "posts/fulton-appeals/index.html",
    "title": "Geospatial Analysis of Fulton County Tax Appeal Filings from 2011 to 2022",
    "section": "",
    "text": "Acknowledgements: Urban Research Group (Brian An, Jenny Moody) for their assistance in understanding Fulton County’s tax parcel and appeals data.\n\n\nGeorgia’s property tax appeal process favors the filer over the county tax office. Appeal filers may pay only 80% of their property taxes when filing an appeal, placing the burden of proof on the county. Regardless the result of the appeal, the property’s assessment will be frozen for the next two successive years 1. There is no limit on filing appeals.\nThese features make the appeals process a target for exploitation. Serial appealers may burden the county’s resources and ability to fairly consider other appeals. This investigation aims to determine which properties are likely to be serial appealers. Presumably, they tend to be owners of high value properties, who stand to benefit despite the time and expense of the appeals process.\nThis article illustrates the geospatial concentration of appeal filers in Fulton County, the seat of the Atlanta metropolitan statistical area. I find a moderate geospatial concentration of serial appealers in north Fulton, partially confirming the hypothesis.\n\n\n\nView the full source code here."
  },
  {
    "objectID": "posts/fulton-appeals/index.html#introduction",
    "href": "posts/fulton-appeals/index.html#introduction",
    "title": "Geospatial Analysis of Fulton County Tax Appeal Filings from 2011 to 2022",
    "section": "",
    "text": "Acknowledgements: Urban Research Group (Brian An, Jenny Moody) for their assistance in understanding Fulton County’s tax parcel and appeals data.\n\n\nGeorgia’s property tax appeal process favors the filer over the county tax office. Appeal filers may pay only 80% of their property taxes when filing an appeal, placing the burden of proof on the county. Regardless the result of the appeal, the property’s assessment will be frozen for the next two successive years 1. There is no limit on filing appeals.\nThese features make the appeals process a target for exploitation. Serial appealers may burden the county’s resources and ability to fairly consider other appeals. This investigation aims to determine which properties are likely to be serial appealers. Presumably, they tend to be owners of high value properties, who stand to benefit despite the time and expense of the appeals process.\nThis article illustrates the geospatial concentration of appeal filers in Fulton County, the seat of the Atlanta metropolitan statistical area. I find a moderate geospatial concentration of serial appealers in north Fulton, partially confirming the hypothesis.\n\n\n\nView the full source code here."
  },
  {
    "objectID": "posts/fulton-appeals/index.html#methods",
    "href": "posts/fulton-appeals/index.html#methods",
    "title": "Geospatial Analysis of Fulton County Tax Appeal Filings from 2011 to 2022",
    "section": "Methods",
    "text": "Methods\n\nData Sources\nAppeals data was kindly provided to the Urban Research Group by the Fulton County Tax Assessor’s Office. For other parcel characteristics, Tax Parcel data (2022) was downloaded from the publicly available Fulton County GIS Portal2. Fulton County cities boundaries were aquired from the ARC Open Data and Mapping Hub3.\n\n\nProcedure\nAppeals data was outer joined to tax parcel data on Parcel ID. The resulting dataframe contains all appeals from 2011 to 2022 with their associated parcel data, and parcels that had no appeals over the period. After confirming both the tax parcel and city boundary dataset had an identical coordinate reference system (CRS), the dataframe was spatially (predicate: within) joined the city boundaries. Each parcel now had a column corresponding to its city name.\n\n\n\n\n\n\nNote\n\n\n\nIt is important to note a minor limitation of this approach. Since tax parcel data is limited only to 2022 but appeals start in 2011, some parcels may have changed throughout the study period. 6.3K parcels could not be matched to the 2022 data, resulting in 273K valid parcels. I believe this limitation is negligable. Our main focus is repeat appealers and a parcel which has changed throughout the period cannot be accurately included.\n\n\nTables were generated with key measures at each level, one that aggreggated appeals at the city level, another at the parcel level, and another by year. While I outline some key decisions here, I encourage viewing the source code for the complete implementation.\nNotably, an appeal is successful if the difference between Notice Assessment and Current Assessment was positive. Notice Assessment is the original tax bill assessment, whereas Current Assessment is the result after a possible adjustment. Therefore, appeals are successful when the tax bill assessment is reduced. The calculated difference in assessment is adjusted for inflation. However, this undercounts the total impact of the appeals process on tax revenue, as detailed in the discussion section.\nOnly successful appeals are considered when calculating the mean and median percent change in assessment. Including all appeals would skew reduce the result towards zero. This calculation may be worth revisitng to understand the mean reduction on a per-parcel level.\nFinally, lost revenue is the sum of tax bill reductions multiplied by 0.00432. Georgia calculates a tax bill by multiplying the property’s assessed value by 40% and then multiplying the resulting value by the millage rate 4. The number I derived is a lower bound estimate of millage rates throughout Fulton County, multiplied by 0.4. Still, this calculation undercounts even further than the lower bound, as discussed in the following section."
  },
  {
    "objectID": "posts/fulton-appeals/index.html#findings",
    "href": "posts/fulton-appeals/index.html#findings",
    "title": "Geospatial Analysis of Fulton County Tax Appeal Filings from 2011 to 2022",
    "section": "Findings",
    "text": "Findings\n\nResults and Visualizations\n\n\n\n\n                                                \n\n\n\n\n\n\n\n\n                                                \n\n\n\n\nAtlanta, with the highest density of parcels and largest land area in the county, has the greatest number of appeals (50% of all appeals) filed within its boundaries.\n\n\n\n\n                                                \n\n\n\n\nThis measure normalizes the metric by accounting for the number of unique parcels in each city. Such a metric provides insight into cities that account for more appeals than expected.\n\n\n\n\n\n\n\n                                                \n\n\n\n\nTaken in context that southern Fulton tends to have lower property values than northern Fulton, this map provides useful insights. There are a relatively high number of parcels in southern Fulton county that file up to five repeat appeals. After five appeals, the distribution begins to shift significantly to Atlanta, Sandy Springs (Buckhead), and northern Fulton, with few parcels in southern Fulton filing repeat appeals beyond this threshold. Such a pattern appears to indicate that more unique parcels in southern Fulton have filed repeat appeals overall, but northern Fulton has a higher share of serial filers. Between five to six appeals appears to be the threshold.\n\n\n\n\n                                                \n\n\n\n\n\n\n\n\n                                                \n\n\n\n\nNo major differences in appeal success rate exists between cities. Sandy Springs, Chattahoochee Hills, Fairburn, and Alpharetta are slightly more successful than average. Mountain Park is an outlier but has a small sample size. Chattahoochee Hills and Fairburn also have few parcels compared to Sandy Springs and Alpharetta. However, no significance test was run for this analysis.\n\n\n\n\n                                                \n\n\n\n\nThe sum of tax bill reductions is heavily dependent on the mean property values of each city. Unsurprisingly, the vast majority of tax bill reductions come from Atlanta, lagged by Sandy Springs. These cities also have a large portion of high value commercial and office space.\n\n\nDiscussion\nMost tax bill reductions in Fulton County come from Atlanta and Sandy Springs (Buckhead). Occasional repeat appealers (5 or less appeals over 12 years) tend to concentrate in southern Fulton where property values are generally low; serial repeat appealers are heavily concentrated in northern Fulton where property values are generally high.\nThis analysis is not exhaustive and no statistical tests were run. Calculating reductions in tax bills using only Notice and Current Assessments undercounts 1) appreciation that would accrue if the assessment was not frozen by the appeal, and 2) any instances of under appraisal both proceeding the appeal and following it. There have been numerous accounts of systemic under appraisal, especially for high value properties. Such practices are largely codified into the apprasial process. This topic should be investigated further."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About",
    "section": "",
    "text": "I’m a Computer Science student and Data Researcher at Georgia Tech’s Urban Research Group, using software, GIS, and data science to highlight the impacts of policy decisions. My work includes developing a fuzzy entity resolution algorithm for parcel ownership analysis and uncovering factors influencing homeownership rates in Atlanta neighborhoods. This research helped identify $101M in lost revenue for Fulton County.\nAt Collins Aerospace, as a Software Engineer - AI/ML Data Platform, I led enhancements to Smartbid, an image processing and OCR data pipeline for mechanical part information extraction.\nMy passion lies in leveraging technology and public policy for a sustainable, equitable world. As an environmental advocate with Citizens’ Climate Lobby, I’ve lobbied for climate policies and previously led the Georgia Tech chapter, gaining support from local leaders.\n\n\n\n\n\n\nNote\n\n\n\nOpen to Full-Time Software and Data Roles Starting May 2024.\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis website is new. To see my previous website, click here."
  },
  {
    "objectID": "posts/fulton-appeals/index.html#footnotes",
    "href": "posts/fulton-appeals/index.html#footnotes",
    "title": "Geospatial Analysis of Fulton County Tax Appeal Filings from 2011 to 2022",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n2022 Georgia Code - Justia↩︎\nFulton County GIS Portal↩︎\nARC Open Data and Mapping Hub↩︎\nGA Department of Revenue↩︎"
  },
  {
    "objectID": "posts/methods-sfr/index.html",
    "href": "posts/methods-sfr/index.html",
    "title": "Discussion on Methods to Identify Institutional Investors from Messy Data",
    "section": "",
    "text": "This is a written version of a presentation I gave to a working group of researchers studying the impact of institutional investors. The session was organized by Anthony Damiano, PhD and hosted by the Center for Urban and Regional Affairs at the University of Minnesota Twin Cities.\n\n\n\n\n\n\nSession Recording Link\n\n\n\nWill add after session\n\n\nA need for accessible and robust methods to identify institutional investors, especially single-family rental (SFR) investors, motivates this discussion. Considering the lack of rental registries in the United States, researchers must bear significant technical burdens in identifying these investors from messy parcel and sales records. The challenges include, but are not limited to: inconsistent naming, corporations with multiple business addresses, and difficulty in acquiring data, especially historical data.\n\n\n\n\n\n\nNote\n\n\n\nI refer to algorithms that identify institutional investors as entity resolution (fuzzy matching) or clustering algorithms, depending on which I am referring to. I use these terms to reflect the general desire to group same-owners (such as subsidary corporations) together within data, even if the exact definition of these algorithms differ. Classification algorithms may also be relevant, but we generally do not have a complete list of investors to supervise learning. I discuss machine learning (clustering, classification, and deep learning) algorithms in more detail later."
  },
  {
    "objectID": "posts/methods-sfr/index.html#introduction",
    "href": "posts/methods-sfr/index.html#introduction",
    "title": "Discussion on Methods to Identify Institutional Investors from Messy Data",
    "section": "",
    "text": "This is a written version of a presentation I gave to a working group of researchers studying the impact of institutional investors. The session was organized by Anthony Damiano, PhD and hosted by the Center for Urban and Regional Affairs at the University of Minnesota Twin Cities.\n\n\n\n\n\n\nSession Recording Link\n\n\n\nWill add after session\n\n\nA need for accessible and robust methods to identify insitutional investors, especially single-family rental (SFR) investors, motivates this discussion. Considering the lack of rental registries in the United States, researchers must bear significant technical burdens in identifying these investors from messy parcel and sales records. The challenges include, but are not limited to: inconsistent naming, corporations with multiple business addresses, and difficulty in acquiring data, especially historical data.\n\n\n\n\n\n\nNote\n\n\n\nI refer to algorithms that identify insitutional investors as entity resolution or clustering algorithms, depending on which I am referring to. I use these terms to reflect the general desire to group same-owners (such as subsidary corporations) together within data, even if the exact definition of these algorithms differ. Classification algorithms may also be relevant, but we generally do not have a complete list of investors to supervise learning. I discuss machine learning (clustering, classification, and deep learning) algorithms in more detail later."
  },
  {
    "objectID": "posts/methods-sfr/index.html#tradeoffs",
    "href": "posts/methods-sfr/index.html#tradeoffs",
    "title": "Discussion on Methods to Identify Institutional Investors from Messy Data",
    "section": "Tradeoffs",
    "text": "Tradeoffs\nWe should first analyze the fundamental challenges of this topic. All methods must make a trade off between accuracy, runtime, and technical complexity.\n\nAccuracy\nFor accuracy, we can prioritize absolute number of matches, percent correct matches, percent true-matches vs false-matches, or some combination of these criteria.\nGenerally, most situations aim to maximize the number of correct matches without crossing a threshold for percent false-matches. Essentially, we want as many matches as possible and most of them need to be correct.\n\n\n\n\n\n\nNote\n\n\n\nWhile accuracy is most important, an ideal algorithm should be precise in that it is invariant to minor changes in data format. Some data may contain, for instance, street postfix abbreviations (e.g. “STREET” or “ST”) within owner address whereas others will not. An ideal algorithm should retain its accuracy and precision regardless of these differences.\n\n\n\n\nRuntime (Time Complexity)\nFor execution time or runtime, needs vary. For practioniers, waiting days for an algorithm to run is not feasible. Researchers are generally more willing to consider these algorithms. We must also consider the hardware each party has access to.\nThere are three potential target categories of runtime, in this context:\n\nGood algorithms that can be run quickly and easily on any hardware,\nBetter algorithms that experienced professionals can run if necessary,\nOptimal algorithms that may require offsite, vast infrastructure.\n\nIt is unlikely that the marginal improvement from categeory 2 to 3 is worth the additional effort. Training a deep learning model may be an exception, as it only requires extensive infrastructure and expertise once during training. We will discuss this further in following sections.\n\n\nTechnical and Implementation Complexity\nTechnical complexity is related to algorithmic effieciency; however, some fast algorithms might be very difficult to implement. For instance, concurrent processing may make an algorithm fast enough for pacticioners to use, but they cannot be expected to implement this themselves.\nThis issue can be resolved with the creation of programmatic tools or applications that facilitate the use of these algorithms."
  },
  {
    "objectID": "posts/methods-sfr/index.html#time-complexity",
    "href": "posts/methods-sfr/index.html#time-complexity",
    "title": "Discussion on Methods to Identify Institutional Investors from Messy Data",
    "section": "Time Complexity",
    "text": "Time Complexity\nLet us further analyze algorithm efficiency, otherwise known as time and space complexity.\nWe are generally more concerned with time complexity. It is relatively cheap to buy RAM but impossible to buy time.\nWe can categorize algorithms with Big-O notation; we write time complexity as O(f(n)), where f(n) is an upper bound function for the runtime of the algorithm given input of size n.\nRuntime does not mean how long it takes to run on any individual computer, but rather the number of operations in the worst case. We also don’t care much about how long these algorithms take to run on very small problems, only as the problems get larger.\n\n\n\nGraph showing the common Big-O notation functions for algorithm complexity. Source."
  },
  {
    "objectID": "posts/methods-sfr/index.html#time-complexity-of-single-comparisons",
    "href": "posts/methods-sfr/index.html#time-complexity-of-single-comparisons",
    "title": "Discussion on Methods to Identify Institutional Investors from Messy Data",
    "section": "Time Complexity of Single Comparisons",
    "text": "Time Complexity of Single Comparisons\n\nVectorized Comparison (Equals Operator): O(1)\nThis is an exact comparison between two encoded values (in this case, strings). A computer can take two binary encodings from memory and compare them exactly with a single operation.\n\n\n\n\n\n\nExample\n\n\n\nBoth \"A\" =? \"A\" and \"1 MAIN ST\" =? \"1 MAIN ST\" take approximately the same time to execute, despite longer strings in the second group.\n\n\n\n\nSimiliarity Metrics or other Iterative Comparison: O(n)\nThese are metrics that calculate a similarity score based on aspects of the string. Many string distance metrics calculate the distance between corresponding letters in a string. This requires a comparison for each letter in the shortest string.\n\n\n\n\n\n\nExample\n\n\n\nRunning Levenshtein Distance, a common string distance metric, on \"A\" =? \"A\" and \"1 MAIN ST\" =? \"1 MAIN ST\" takes 1 and 9 operations to execute, respectively."
  },
  {
    "objectID": "posts/methods-sfr/index.html#time-complexity-of-entity-resolution-algorithms",
    "href": "posts/methods-sfr/index.html#time-complexity-of-entity-resolution-algorithms",
    "title": "Discussion on Methods to Identify Institutional Investors from Messy Data",
    "section": "Time Complexity of Entity Resolution Algorithms",
    "text": "Time Complexity of Entity Resolution Algorithms\n\nAggreggate / GroupBy: O(n)\nThese functions utilize the same efficiencies of vectorized comparison by hashing values and placing them into blocks/buckets.\n\n\n\n\n\n\nExample (Python Pandas)\n\n\n\ndata.groupby(\"owner_address\")\n\n\n\n\nSimilarity Threshold Grouping: O(n^2)\nThese functions typically compare each string to every other string using a similarity metric, grouping strings that are above a certain threshold.\nRuntime may be improved with blocking or concurrency; OpenRefine’s clustering function appears to use an optimized implementation.\n\n\n\n\n\n\nExample (OpenRefine)\n\n\n\nPlease refer to (open?)"
  },
  {
    "objectID": "posts/methods-sfr/index.html#time-complexity-of-machine-learning-algorithms",
    "href": "posts/methods-sfr/index.html#time-complexity-of-machine-learning-algorithms",
    "title": "Discussion on Methods to Identify Institutional Investors from Messy Data",
    "section": "Time Complexity of Machine Learning Algorithms",
    "text": "Time Complexity of Machine Learning Algorithms\n\nK-Nearest Neighbors (Clustering, Unsupervised): O(n^2)\nThis algorithm encodes strings as vectors in a multi-dimensional space. Then, it compares each vector to every other vector using a vector distance metric (like cosine similarity), finding the k closest vectors, where k is user-defined. It is the foundation of clustering algorithms.\nSome specialized versions of this algorithm, like metric trees, are more optimized.\n\n\n\nKNN visualization (H., n.d.)\n\n\n\n\nApproximate K-Nearest Neighbors (Clustering, Unsupervised): generally at or below O(n)\nThis is a modified form of K-Nearest Neighbors that trades perfect accuracy for speed. It uses an efficient algorithm to split the vector space into subspaces. Rather than comparing a vector to every other vector, it utilizes the subspaces to quickly identify where the most similar vectors likely are.\n\n\n\n\n\n\nExample ANN Algorithms\n\n\n\n\nFAISS\nLocality-Sensitive Hashing (LSH)\nHierarchical Navigable Small World (HNSW)\n\n\n\n\n\n\nVisualization of subspaces in ANN (Bernhardsson, n.d.)\n\n\n\n\nDeep Learning (Classification, Supervised): O(n^n)*\nDeep learning uses a series of subsequent layers to transform data into a final layer (categories). Within each layer, there are nodes which each contain a separate activation function. The model is trained by feeding input data and comparing its output to the desired output; the nodes are modified with each data point to optimize the result.\nTraining a deep learning model typically requires dedicated GPUs, but once the model is trained, it can be used much more efficiently.\n\n\n\n  \n    \n  \n  deeplearning\n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n    \n  \n  \n    \n    \n    \n  \n  \n    \n    \n    \n  \n  \n    \n    \n    \n  \n  \n    \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n\nSimplified deep learning architecture. Source.\n\n\n\n\n\n\n\n\n*Note on Runtime Complexity\n\n\n\nRuntime complexity depends on the implementation. However, the entire dataset will not be used during training, and training only needs to occur once, not every time the model is used."
  },
  {
    "objectID": "posts/methods-sfr/index.html#approaches",
    "href": "posts/methods-sfr/index.html#approaches",
    "title": "Discussion on Methods to Identify Institutional Investors from Messy Data",
    "section": "Approaches",
    "text": "Approaches\n\nSimple Address Key\nFor each parcel, we construct an owner address key by concatenating the address number, address string (street name or PO Box), and zip code. Because the address string excludes postfixes, we can avoid some missed matches due to inconsistencies between labeling, such as “STREET” vs. “ST”. Before creating the key, we eliminate various other inconsistencies by removing periods, commas, multiple spaces, and uppercasing all characters. Finally, to resolve inconsistencies for PO boxes, we can take any address string with at least one number, extract the numbers, and postpend them to the string literal “PO BOX”. In our Fulton County SF parcel data, after completing this procedure, all PO Boxes were standardized except 37 (of 63K) malformed address strings which were dropped accordingly.\nTable 1. Examples of Owner Address Key Procedure\n\n\n\n\n\n\n\n\n\nAddress Number\nAddress String\nZip Code\nAddress Key\n\n\n\n\n52\nCREEKSIDE PARK\n30022\n52 CREEKSIDE PARK 30022\n\n\nNA (filled with 0)\nP.O. BOX 370049\n30037\n0 PO BOX 370049 30037\n\n\nNA (filled with 0)\nP O Box 370049\n30037\n0 PO BOX 370049 30037\n\n\n\n\n\nAdvanced Address Key (BR)\n\n\nCustom Similarity Functions"
  },
  {
    "objectID": "posts/methods-sfr/index.html#conclusion",
    "href": "posts/methods-sfr/index.html#conclusion",
    "title": "Discussion on Methods to Identify Institutional Investors from Messy Data",
    "section": "Conclusion",
    "text": "Conclusion\nUntil rental registries are established, these challenges will continue to limit actionable and evidence-based policymaking for the housing market. It is essential that we quickly uncover significant evidence to urge policymakers to act before corporations find new ways to obfusicate ownership."
  },
  {
    "objectID": "posts/methods-sfr/index.html#questions-and-answers-from-the-live-session",
    "href": "posts/methods-sfr/index.html#questions-and-answers-from-the-live-session",
    "title": "Discussion on Methods to Identify Institutional Investors from Messy Data",
    "section": "Questions and Answers from the Live Session",
    "text": "Questions and Answers from the Live Session\nWill be recorded here after the conclusion of the session."
  },
  {
    "objectID": "posts/methods-sfr/index.html#proposal-methods-paper-to-establish-a-more-definitive-answer",
    "href": "posts/methods-sfr/index.html#proposal-methods-paper-to-establish-a-more-definitive-answer",
    "title": "Discussion on Methods to Identify Institutional Investors from Messy Data",
    "section": "Proposal: Methods Paper to Establish a More Definitive Answer",
    "text": "Proposal: Methods Paper to Establish a More Definitive Answer\n\nComparing All Methods\n\n\nOptimized Coding Tools"
  },
  {
    "objectID": "posts/methods-sfr/index.html#current-approaches",
    "href": "posts/methods-sfr/index.html#current-approaches",
    "title": "Discussion on Methods to Identify Institutional Investors from Messy Data",
    "section": "Current Approaches",
    "text": "Current Approaches\n\nSimple Address Key\nIn my paper with Brian An, Uncovering Neighborhood-level Portfolios of Corporate Single-Family Rental Holdings and Equity Loss, our priority was developing a simple method to accurately quantify ownership scale, rather than identify the portolfios of specific owners. However, this is possible with an additional querying method. This section details these methods.\nMotivation and Design\n\nWe rely on a modified version of the owner address to group the same-owners together. Owner address has a lower potential for false positive matches than owner name while also being easier to standardize and correctly match. Moreover, owner name has greater potential for inconsistency between subsidiary corporations, but many subsidiary or shell SFR corporations use the same address. In this way, we account for many cases of nested ownership structure, where different holding corporations may own properties, but report the same business address for records purposes. We favor this approach as it narrows focus to our research question without opaque or complex methodological underpinnings.\n\nIn particular, by using an encodable key for each address, this method takes advantage of vectorized comparison. Therefore, it can use a aggreggate or groupby operation for a runtime complexity of O(n).\nMethod Details\n\nFor each parcel, we construct an owner address key by concatenating the address number, address string (street name or PO Box), and zip code. Because the address string excludes postfixes, we can avoid some missed matches due to inconsistencies between labeling, such as “STREET” vs. “ST”. Before creating the key, we eliminate various other inconsistencies by removing periods, commas, multiple spaces, and uppercasing all characters. Finally, to resolve inconsistencies for PO boxes, we can take any address string with at least one number, extract the numbers, and postpend them to the string literal “PO BOX”.\n\n\n\n\n\n\n\nTable 1. Examples of Owner Address Key Procedure\n\n\n\n\n\n\n\n\n\n\n\n\nAddress Number\nAddress String\nZip Code\nAddress Key\n\n\n\n\n52\nCREEKSIDE PARK\n30022\n52 CREEKSIDE PARK 30022\n\n\nNA (filled with 0)\nP.O. BOX 370049\n30037\n0 PO BOX 370049 30037\n\n\nNA (filled with 0)\nP O Box 370049\n30037\n0 PO BOX 370049 30037\n\n\n\n\n\n\n\n\n\n\n\nTable 2. Sample of Corporate Owners and Associated Subsidaries\n\n\n\n\n\n\n\n\n\n\n\nOwner Address Key\nSample of Associated Names\nCommon Name\n\n\n\n\n5001 PLAZA ON THE 78746\nALTO ASSET COMPANY 2 LLC, EPH 2 ASSETS LLC, BAF 1 LLC\nAmherst Residential\n\n\n1850 PARKWAY 30067\nFKH SFR PROPCO D L P, CERBERUS SFR HOLDINGS LP\nFirstKey Homes (Cerberus Capital)\n\n\nPO BOX 4090 85261\nHOME SFR BORROWER IV LLC, PROGRESS RESIDENTIAL BORROWER 15 LLC\nProgress Residential\n\n\n1717 MAIN 75201\n2018 3 IH BORROWER LP, 2018 2 IH BORROWER LP\nInvitation Homes\n\n\n591 PUTNAM 6830\nSTAR 2021-SFR2 BORROWER L P, STAR 2021 SFR2 BORROWER LP\nColony Starwood Homes\n\n\n\n\n\n\n\n\n\n\n\nQuerying\n\n\n\nMotivation\nDue to the possibility that the same corporation may use multiple addresses, the address key method is not intended to robustly describing the portfolios of specific corporate owners. However, it is possible to query the resulting data (in this example, we label the table ownership scale) for this information.\nSteps\n\nProduce an aggregated owner table by aggregating on address key\nCreate a list of substrings associated with the desired owner (for instance, “AMHERST” and “ARVM” for “Amherst”).\nIdentify rows where at least one associated owner name contains the substring\nOptional: apply a threshold\n\n\n\n\n\n\n\nNote\n\n\n\nIn the case that a complete list of substrings for each owner is not known, it is possible to begin querying with the base name or other substrings that are known. From this result, add more potentially subtrings.\nFor instance, only query with “Amherst”, then look through the resulting associated names. This is why we added “ARVM” as a substring key. In our experience, most substrings or other types of patterns appear for multiple addresses, so it is possible to quickly identify the most common substrings.\n\n\nCode Example (Python)\n# Keywords to query for each owner\n# For short strings, like \"IH\" that might accidentally appear,\n# a space is added to reduce this possibility.\nowner_keywords = {\n    \"Amherst\": [\"AMHERST\", \"ARVM\"],\n    \"Cerberus\": [\"CERBERUS\", \"FKH\", \"RM1 \", \"RMI \"],\n    \"Progress\": [\"PROGRESS\", \"FYR\"],\n    \"Invitation\": [\"INVITATION\", \"IH \"],\n    \"Colony\": [\"COLONY\", \"STARWOOD\", \"CSH\", \"CAH \"],\n    \"Sylvan\": [\"SYLVAN\", \"RNTR\"],\n    \"Tricon\": [\"TRICON\", \"TAH\"]\n}\n\n# Query for each owner described above\nfor owner in owner_keywords:\n    query_str = \"|\".join(owner_keywords[owner])\n\n    # Find rows for TAXYR 2020 and where at least one associated name\n    # contains a keyword matching the owner\n    owned_by_given_corp = owner_scale[\n        (owner_scale[\"TAXYR\"] == 2020) \n        & owner_scale[\"assoc_owner_names\"].apply(\n            lambda x: any(((re.search(query_str, name)) for name in x)\n        ))\n    ]\n\n    # Only retain matched subsidary owners over a threshold,\n    # this is to prevent false positive matches. For instance,\n    # if a single parcel was owned by someone with the last name \"SYLVAN\"\n    owned_by_given_corp = owned_by_given_corp[\n        owned_by_given_corp[\"count_owned_fulton_yr\"] &gt; 49\n    ]\n    \n    # Sum total over all matched subsidaries\n    total_owned = owned_by_given_corp[\"count_owned_fulton_yr\"].sum()\n\n\n\n\n\n\nTable 3. Example Output: SFR Ownership Scale of Top 5 Corporate Landlords in Fulton County in 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nParcels Owned in Fulton (Address Key Query)\nOpenRefine (OR) method (An et al. 2024)\nNet Diff.\nOR method + manual review (An et al. 2024)\nNet Diff.\n\n\n\n\nAmherst Residential\n720\n103\n+617\n750\n-30\n\n\nInvitation Homes\n677\n524\n+153\n719\n-42\n\n\nProgress Residential\n619\n457\n+159\n760\n-141\n\n\nSylvan Realty (RNTR)\n422\n250\n+172\n433\n-11\n\n\nTricon Residential\n219\n222\n-3\n280\n-61\n\n\nCerberus Capital\n256\n340\n-86\n349\n-93\n\n\nStarwood Capital\n122\n361\n-239\n450\n-328\n\n\n\n\n\n\n\n\n\nAdvanced Address Key\nThe Simple Address Key has difficulty with precision; on differently formatted data, it may struggle. For instance, if “ST” or “STREET” are included in the address string. It also does not account for different SUITE numbers. Additionally, there may be other minor inconsistencies due to unforeseen issues like spelling or word order which are impossible to clean.\nA more complex address key can be formulated with this in mind, but both the technical complexity and runtime complexity increase.\nThe simplest form of an Advanced Address Key extracts the address number, the suite number, the zip code, and the last two letters of the longest substring in the street address. Such features are almost always invariate to changes in spelling, word order, street postfixes, or other inconsistencies.\nAddress number and suite number can be identified as the first and last series of numbers, separated by spaces. A REGEX pattern can be used to extract these numbers.\n\n\n\n\n\n\nTable 4. Example Advanced Address Key Matching\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAddress 1\nZip 1\nADDR KEY 1\nAddress 2\nZip 2\nADDR KEY 2\nMatched?\n\n\n\n\nPO BOX 490734\n30363\n490734-0-OX30363\nP O. BOX 490734\n30363\n490734-0-OX30363\nYes\n\n\n3505 KOGER BLVD 400\n30315\n3505-400-ER30315\n3505 KOGER BLVD., SUITE 400\n30315\n3505-400-ER30315\nYes\n\n\nOne Buckhead PL STE 300\n30305\n1-300-AD-30305\nOne Buckhead PL STE 325\n30303\n1-325-AD-30305\nNo\n\n\n5 PEACHTREE ST\n30308\n5-0-30308\n5 PEACHTREE ST\n30354\n5-0-30354\nNo\n\n\n\n\n\n\n\n\n\n\n\nAuto-Querying (Aggregation) with Business Registry Data\n\n\n\nblah\n\n\n\n\n\n\n\n\nCrowdsourcing Rental Registries\n\n\n\nblah\n\n\n\n\nCustom Similarity Metrics\nWhile key methods are ideal for applications that require fast computation or lack computational power, some use of string similarity metrics may be advantageous for those with the capability.\nThe use of string similarity metrics becomes more useful for ambigious cases, or for grouping owners with similiar names but different addresses. The efficiency may also be increased by blocking; for instance, using a vectorized aggregation to create buckets of owners with at least one matching word substring; doing so reduces the number of necessary comparisons exponentially.\nHowever, most string distance metrics are not optimized for address strings or corporate owner names. They are typically best for spelling inconsistencies. Therefore, developing a string distance metric optimized for corporate names has potential.\nMy experience indicates that such a string distance metric should prioritze token comparison over letter comparison.\nFor instance, “2018 3 IH BORROWER LP” and “HOME SFR BORROWER IV LLC” have many letters in common, but they are different entities. More weight should be placed on the substrings, like “IH” and “HOME”, since common terms like “SFR” and “BORROWER” appear frequently.\nThis warrants further investigation as the most common string distance metrics have a high number of false positives in our use case."
  },
  {
    "objectID": "posts/methods-sfr/index.html#a-methods-paper-to-establish-a-more-definitive-answer",
    "href": "posts/methods-sfr/index.html#a-methods-paper-to-establish-a-more-definitive-answer",
    "title": "Discussion on Methods to Identify Institutional Investors from Messy Data",
    "section": "A Methods Paper to Establish a More Definitive Answer",
    "text": "A Methods Paper to Establish a More Definitive Answer\nFor each research question that necesitates the classification or identification of property ownership, researchers must spend valuable time wrangling with these challenges. Practioners too, can gain valuable insights from this analysis, but lack the resources or knowledge to overcome these barriers.\nTo reduce the burden on researchers and increase the speed at which the impact of SFR investment can be studied, a methods paper should concretely compare all current methods.\nThe goal of this project would be to produce:\n\nA paper comparing all methods, highlighting the tradeoffs for each, and which methods are best depending on the circumstance\nOptimized coding tools or an application to faciliate the best procedures\n\n\nComparing All Methods\n\n\nOptimized Coding Tools"
  },
  {
    "objectID": "posts/methods-sfr/index.html#qa-from-the-live-session",
    "href": "posts/methods-sfr/index.html#qa-from-the-live-session",
    "title": "Discussion on Methods to Identify Institutional Investors from Messy Data",
    "section": "Q&A from the Live Session",
    "text": "Q&A from the Live Session\nWill be recorded here after the conclusion of the session."
  },
  {
    "objectID": "posts/methods-sfr/index.html#a-methods-paper-to-reduce-these-challenges",
    "href": "posts/methods-sfr/index.html#a-methods-paper-to-reduce-these-challenges",
    "title": "Discussion on Methods to Identify Institutional Investors from Messy Data",
    "section": "A Methods Paper to Reduce These Challenges",
    "text": "A Methods Paper to Reduce These Challenges\nFor each research question that necesitates the classification or identification of property ownership, researchers must spend valuable time wrangling with these challenges. Practioners can also gain valuable insights from this analysis, but lack the resources or knowledge to overcome these barriers.\nTo reduce the burden on researchers and increase the speed at which the impact of SFR investment can be studied, a methods paper should concretely compare all current methods.\nThe goal of this speculative project is to produce:\n\nA sample of labeled data (ground truth) across multiple metros areas to train and/or test models against.\nA paper comparing all (and potential) methods, highlighting the tradeoffs for each, and which methods are best for under specific circumstances.\nOptimized coding tools or an application to faciliate the best procedures."
  },
  {
    "objectID": "posts/methods-sfr/index.html#my-thoughts-on-an-optimal-solution-and-conclusion",
    "href": "posts/methods-sfr/index.html#my-thoughts-on-an-optimal-solution-and-conclusion",
    "title": "Discussion on Methods to Identify Institutional Investors from Messy Data",
    "section": "My Thoughts on An Optimal Solution and Conclusion",
    "text": "My Thoughts on An Optimal Solution and Conclusion\nUntil rental registries are established, these challenges will continue to limit actionable and evidence-based policymaking for the housing market. It is essential that we quickly uncover significant evidence to urge policymakers to act before corporations find new ways to obfusicate ownership."
  },
  {
    "objectID": "posts/methods-sfr/index.html#accuracy",
    "href": "posts/methods-sfr/index.html#accuracy",
    "title": "Discussion on Methods to Identify Institutional Investors from Messy Data",
    "section": "Accuracy",
    "text": "Accuracy\nFor accuracy, we can prioritize absolute number of matches, percent correct matches, percent true-matches vs false-matches, or some combination of these criteria.\nGenerally, most situations aim to maximize the number of correct matches without crossing a threshold for percent false-matches. Essentially, we want as many matches as possible and most of them need to be correct.\n\n\n\n\n\n\nNote\n\n\n\nWhile accuracy is most important, an ideal algorithm should be precise or otherwise invariant to minor changes in data format. Some data may contain, for instance, street postfix abbreviations (e.g. “STREET” or “ST”) within owner address whereas others will not. An ideal algorithm should retain its accuracy and precision regardless of these differences."
  },
  {
    "objectID": "posts/methods-sfr/index.html#runtime-time-complexity",
    "href": "posts/methods-sfr/index.html#runtime-time-complexity",
    "title": "Discussion on Methods to Identify Institutional Investors from Messy Data",
    "section": "Runtime (Time Complexity)",
    "text": "Runtime (Time Complexity)\nFor execution time or runtime, needs vary. For practioniers, waiting days for an algorithm to run is not feasible. Researchers are generally more willing to consider these algorithms. We must also understand limitations of the hardware each party has access to.\nIn this context, there are three potential target categories of runtime:\n\nGood algorithms that can be run quickly and easily on any hardware,\nBetter algorithms that experienced professionals can run if necessary,\nOptimal algorithms that may require offsite, vast infrastructure.\n\nIt is unlikely that the marginal improvement from categeory 2 to 3 is worth the additional effort. Training a deep learning model may be an exception, as it only requires extensive infrastructure and expertise once during training. We will discuss this further in following sections."
  },
  {
    "objectID": "posts/methods-sfr/index.html#technical-and-implementation-complexity",
    "href": "posts/methods-sfr/index.html#technical-and-implementation-complexity",
    "title": "Discussion on Methods to Identify Institutional Investors from Messy Data",
    "section": "Technical and Implementation Complexity",
    "text": "Technical and Implementation Complexity\nTechnical complexity is often related to algorithmic effieciency; however, some fast algorithms might be very difficult to implement. For instance, concurrent processing may make an algorithm fast enough for pacticioners to use, but they cannot be expected to implement this themselves.\nThis issue can be resolved with the creation of programmatic tools or applications that facilitate the use of these algorithms."
  },
  {
    "objectID": "posts/methods-sfr/index.html#simple-address-key",
    "href": "posts/methods-sfr/index.html#simple-address-key",
    "title": "Discussion on Methods to Identify Institutional Investors from Messy Data",
    "section": "Simple Address Key",
    "text": "Simple Address Key\nIn my paper with Brian An, Uncovering Neighborhood-level Portfolios of Corporate Single-Family Rental Holdings and Equity Loss, our priority was developing a simple method to accurately quantify ownership scale, rather than identify the portolfios of specific owners (Polimeni and An 2024). However, this is possible with an additional querying method. This section details these methods.\nMotivation and Design\n\nWe rely on a modified version of the owner address to group the same-owners together. Owner address has a lower potential for false positive matches than owner name while also being easier to standardize and correctly match. Moreover, owner name has greater potential for inconsistency between subsidiary corporations, but many subsidiary or shell SFR corporations use the same address. In this way, we account for many cases of nested ownership structure, where different holding corporations may own properties, but report the same business address for records purposes. We favor this approach as it narrows focus to our research question without opaque or complex methodological underpinnings.\n\nIn particular, by using an encodable key for each address, this method takes advantage of vectorized comparison. Therefore, it can use a aggreggate or groupby operation for a runtime complexity of O(n).\nMethod Details\n\nFor each parcel, we construct an owner address key by concatenating the address number, address string (street name or PO Box), and zip code. Because the address string excludes postfixes, we can avoid some missed matches due to inconsistencies between labeling, such as “STREET” vs. “ST”. Before creating the key, we eliminate various other inconsistencies by removing periods, commas, multiple spaces, and uppercasing all characters. Finally, to resolve inconsistencies for PO boxes, we can take any address string with at least one number, extract the numbers, and postpend them to the string literal “PO BOX”.\n\n\n\n\n\n\n\nTable 1. Examples of Owner Address Key Procedure\n\n\n\n\n\n\n\n\n\n\n\n\nAddress Number\nAddress String\nZip Code\nAddress Key\n\n\n\n\n52\nCREEKSIDE PARK\n30022\n52 CREEKSIDE PARK 30022\n\n\nNA (filled with 0)\nP.O. BOX 370049\n30037\n0 PO BOX 370049 30037\n\n\nNA (filled with 0)\nP O Box 370049\n30037\n0 PO BOX 370049 30037\n\n\n\n\n\n\n\n\n\n\n\nTable 2. Sample of Corporate Owners and Associated Subsidaries\n\n\n\n\n\n\n\n\n\n\n\nOwner Address Key\nSample of Associated Names\nCommon Name\n\n\n\n\n5001 PLAZA ON THE 78746\nALTO ASSET COMPANY 2 LLC, EPH 2 ASSETS LLC, BAF 1 LLC\nAmherst Residential\n\n\n1850 PARKWAY 30067\nFKH SFR PROPCO D L P, CERBERUS SFR HOLDINGS LP\nFirstKey Homes (Cerberus Capital)\n\n\nPO BOX 4090 85261\nHOME SFR BORROWER IV LLC, PROGRESS RESIDENTIAL BORROWER 15 LLC\nProgress Residential\n\n\n1717 MAIN 75201\n2018 3 IH BORROWER LP, 2018 2 IH BORROWER LP\nInvitation Homes\n\n\n591 PUTNAM 6830\nSTAR 2021-SFR2 BORROWER L P, STAR 2021 SFR2 BORROWER LP\nColony Starwood Homes\n\n\n\n\n\n\n\n\n\n\n\nQuerying\n\n\n\nMotivation\nDue to the possibility that the same corporation may use multiple addresses, the address key method is not intended to robustly describing the portfolios of specific corporate owners. However, it is possible to query the resulting data (in this example, we label the table ownership scale) for this information.\nSteps\n\nProduce an aggregated owner table by aggregating on address key\nCreate a list of substrings associated with the desired owner (for instance, “AMHERST” and “ARVM” for “Amherst”).\nIdentify rows where at least one associated owner name contains the substring\nOptional: apply a threshold\n\n\n\n\n\n\n\nNote\n\n\n\nIn the case that a complete list of substrings for each owner is not known, it is possible to begin querying with the base name or other substrings that are known. From this result, add more potentially subtrings.\nFor instance, only query with “Amherst”, then look through the resulting associated names. This is why we added “ARVM” as a substring key. In our experience, most substrings or other types of patterns appear for multiple addresses, so it is possible to quickly identify the most common substrings.\n\n\nCode Example (Python)\n# Keywords to query for each owner\n# For short strings, like \"IH\" that might accidentally appear,\n# a space is added to reduce this possibility.\nowner_keywords = {\n    \"Amherst\": [\"AMHERST\", \"ARVM\"],\n    \"Cerberus\": [\"CERBERUS\", \"FKH\", \"RM1 \", \"RMI \"],\n    \"Progress\": [\"PROGRESS\", \"FYR\"],\n    \"Invitation\": [\"INVITATION\", \"IH \"],\n    \"Colony\": [\"COLONY\", \"STARWOOD\", \"CSH\", \"CAH \"],\n    \"Sylvan\": [\"SYLVAN\", \"RNTR\"],\n    \"Tricon\": [\"TRICON\", \"TAH\"]\n}\n\n# Query for each owner described above\nfor owner in owner_keywords:\n    query_str = \"|\".join(owner_keywords[owner])\n\n    # Find rows for TAXYR 2020 and where at least one associated name\n    # contains a keyword matching the owner\n    owned_by_given_corp = owner_scale[\n        (owner_scale[\"TAXYR\"] == 2020) \n        & owner_scale[\"assoc_owner_names\"].apply(\n            lambda x: any(((re.search(query_str, name)) for name in x)\n        ))\n    ]\n\n    # Only retain matched subsidary owners over a threshold,\n    # this is to prevent false positive matches. For instance,\n    # if a single parcel was owned by someone with the last name \"SYLVAN\"\n    owned_by_given_corp = owned_by_given_corp[\n        owned_by_given_corp[\"count_owned_fulton_yr\"] &gt; 49\n    ]\n    \n    # Sum total over all matched subsidaries\n    total_owned = owned_by_given_corp[\"count_owned_fulton_yr\"].sum()\n\n\n\n\n\n\nTable 3. Example Output: SFR Ownership Scale of Top 5 Corporate Landlords in Fulton County in 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nParcels Owned in Fulton (Address Key Query)\nOpenRefine (OR) method (An et al. 2024)\nNet Diff.\nOR method + manual review (An et al. 2024)\nNet Diff.\n\n\n\n\nAmherst Residential\n720\n103\n+617\n750\n-30\n\n\nInvitation Homes\n677\n524\n+153\n719\n-42\n\n\nProgress Residential\n619\n457\n+159\n760\n-141\n\n\nSylvan Realty (RNTR)\n422\n250\n+172\n433\n-11\n\n\nTricon Residential\n219\n222\n-3\n280\n-61\n\n\nCerberus Capital\n256\n340\n-86\n349\n-93\n\n\nStarwood Capital\n122\n361\n-239\n450\n-328\n\n\n\n\n\n\n\n\n\n\n\n\n\nAuto-Querying with NLP\n\n\n\nRather than manually building a set of substrings for each corporation, it may be possible to start with a single substring (say, “Amherst”) and find all associated owner names based on the address key method. Then, using an NLP technique, automatically identify the most unique substrings (“ARVM” should appear as this is an unusual combination of letters) and query for those."
  },
  {
    "objectID": "posts/methods-sfr/index.html#advanced-address-key",
    "href": "posts/methods-sfr/index.html#advanced-address-key",
    "title": "Discussion on Methods to Identify Institutional Investors from Messy Data",
    "section": "Advanced Address Key",
    "text": "Advanced Address Key\nThe Simple Address Key has difficulty with precision; on differently formatted data, it may struggle. For instance, if “ST” or “STREET” are included in the address string. It also does not account for different SUITE numbers. Additionally, there may be other minor inconsistencies due to unforeseen issues like spelling or word order which are impossible to clean.\nA more complex address key can be formulated with this in mind, but both the technical complexity and runtime complexity increase.\nThe simplest form of an Advanced Address Key extracts the address number, the suite number, the zip code, and the last two letters of the longest substring in the street address. Such features are almost always invariate to changes in spelling, word order, street postfixes, or other inconsistencies.\nAddress number and suite number can be identified as the first and last series of numbers, separated by spaces. A REGEX pattern can be used to extract these numbers.\n\n\n\n\n\n\nTable 4. Example Advanced Address Key Matching\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAddress 1\nZip 1\nADDR KEY 1\nAddress 2\nZip 2\nADDR KEY 2\nMatched?\n\n\n\n\nPO BOX 490734\n30363\n490734-0-OX30363\nP O. BOX 490734\n30363\n490734-0-OX30363\nYes\n\n\n3505 KOGER BLVD 400\n30315\n3505-400-ER30315\n3505 KOGER BLVD., SUITE 400\n30315\n3505-400-ER30315\nYes\n\n\nOne Buckhead PL STE 300\n30305\n1-300-AD-30305\nOne Buckhead PL STE 325\n30303\n1-325-AD-30305\nNo\n\n\n5 PEACHTREE ST\n30308\n5-0-30308\n5 PEACHTREE ST\n30354\n5-0-30354\nNo\n\n\n\n\n\n\n\n\n\n\n\nImprovements with Business Registry Data\n\n\n\nAvailability of usable state business registry data may vary, so I have not included it in the base algorithm. However, if available, it has potential to aggreggate same-owners that use multiple addresses. The exact implementation may vary with different data schemas.\nFor instance, an owner might record multiple owner addresses for different parcel records, but have a sinlge business address registered with the state. This offers the possibility of exact matching the owner name to business registry data, although this has the same challenges of spelling and naming inconsistencies.\nIn some cases, business registry data may list owner, or beneficial, corporations and their addresses. These can be used to aggregate subsidary addresses and names at the state level.\nRegardless, considering data inconsistency, to match even good data from business registry records to parcel or sales records requires the use of fuzzy matching algorithms discussed here.\n\n\n\n\n\n\n\n\nCrowdsourcing Rental Registries\n\n\n\nUsing an address key approach, we can construct a list of owners associated with a business address. To create a comprehensive list that identifies the portfolios of specific investors, we need to aggregate these lists with querying (see Simple Address Key querying).\nIf researchers complete this step within their own metro areas, we can combine this data to create a robust, crowdsourced ownership database. This database may consist of two tables, one linking address keys to an owner index, and another linking owner indexes to all associated corporate names. With this method, we can efficiently create a linkage between all of a corporate owner’s addresses and corporate names.\n\n\n\n\n\n\nTable 5. Example Schema of Ownership Database (Addresses)\n\n\n\n\n\n\nAddress Key\nOwner Index\n\n\n\n\n5001 PLAZA ON THE 78746\n1\n\n\n9800 HILLWOOD 76177\n2\n\n\n1850 PARKWAY 30067\n2\n\n\n\n\n\n\n\n\n\n\n\nTable 6. Example Schema of Ownership Database (Associated Names)\n\n\n\n\n\n\n\n\n\n\n\nOwner Index\nAssociated Names\nCommon Name\n\n\n\n\n1\nALTO ASSET COMPANY 2 LLC, EPH 2 ASSETS LLC, BAF 1 LLC\nAmherst Residential\n\n\n2\nFKH SFR PROPCO D L P, CERBERUS SFR HOLDINGS LP\nFirstKey Homes\n\n\n\n\n\nAppendix C of my paper (Polimeni and An 2024) contains this data for Fulton County, GA."
  },
  {
    "objectID": "posts/methods-sfr/index.html#custom-similarity-metrics",
    "href": "posts/methods-sfr/index.html#custom-similarity-metrics",
    "title": "Discussion on Methods to Identify Institutional Investors from Messy Data",
    "section": "Custom Similarity Metrics",
    "text": "Custom Similarity Metrics\nWhile key methods are ideal for applications that require fast computation or lack computational power, some use of string similarity metrics may be advantageous for those with the capability.\nThe use of string similarity metrics becomes more useful for ambigious cases, or for grouping owners with similiar names but different addresses. The efficiency may also be increased by blocking; for instance, using a vectorized aggregation to create buckets of owners with at least one matching word substring; doing so reduces the number of necessary comparisons exponentially.\nHowever, most string distance metrics are not optimized for address strings or corporate owner names. They are typically best for spelling inconsistencies. Therefore, developing a string distance metric optimized for corporate names has potential.\nMy experience indicates that such a string distance metric should prioritze token comparison over letter comparison.\nFor instance, “2018 3 IH BORROWER LP” and “HOME SFR BORROWER IV LLC” have many letters in common, but they are different entities. More weight should be placed on the substrings, like “IH” and “HOME”, since common terms like “SFR” and “BORROWER” appear frequently.\nThis warrants further investigation as the most common string distance metrics have a high number of false positives in our use case."
  },
  {
    "objectID": "posts/methods-sfr/index.html#time-complexity-of-string-comparisons",
    "href": "posts/methods-sfr/index.html#time-complexity-of-string-comparisons",
    "title": "Discussion on Methods to Identify Institutional Investors from Messy Data",
    "section": "Time Complexity of String Comparisons",
    "text": "Time Complexity of String Comparisons\nThese comparisons are the building blocks of entity resolution algorithms.\n\nVectorized Comparison (Equals Operator): O(1)\nThis is an exact comparison between two encoded values (in this case, strings). A computer can take two binary encodings from memory and compare them exactly with a single operation.\n\n\n\n\n\n\nExample\n\n\n\nBoth \"A\" =? \"A\" and \"1 MAIN ST\" =? \"1 MAIN ST\" take approximately the same time to execute, despite longer strings in the second group.\n\n\n\n\nSimiliarity Metrics or Other Iterative Comparisons: O(n)\nThese are metrics that calculate a similarity score based on aspects of two strings. Many string distance metrics calculate the “distance” between corresponding letters in each string. This requires a comparison for each letter in the shortest string.\n\n\n\n\n\n\nExample\n\n\n\nRunning Levenshtein Distance, a common string distance metric, on \"A\" =? \"A\" and \"1 MAIN ST\" =? \"1 MAIN ST\" takes 1 and 9 operations to execute, respectively."
  },
  {
    "objectID": "posts/methods-sfr/index.html#string-similarity-metrics",
    "href": "posts/methods-sfr/index.html#string-similarity-metrics",
    "title": "Discussion on Methods to Identify Institutional Investors from Messy Data",
    "section": "String Similarity Metrics",
    "text": "String Similarity Metrics\nWhile key methods are ideal for applications that require fast computation or lack computational power, some use of string similarity metrics may be advantageous for those with the capability.\nThe use of string similarity metrics becomes more useful for ambigious cases, or for grouping owners with similiar names but different addresses. The efficiency may also be increased by blocking; for instance, using a vectorized aggregation to create buckets of owners with at least one matching word substring; doing so reduces the number of necessary comparisons exponentially.\nHowever, most string distance metrics are not optimized for address strings or corporate owner names. They are typically best for spelling inconsistencies. Therefore, developing a string distance metric optimized for corporate names has potential.\nMy experience indicates that such a string distance metric should prioritze token comparison over letter comparison.\nFor instance, “2018 3 IH BORROWER LP” and “HOME SFR BORROWER IV LLC” have many letters in common, but they are different entities. More weight should be placed on the substrings, like “IH” and “HOME”, since common terms like “SFR” and “BORROWER” appear frequently.\nThis warrants further investigation as the most common string distance metrics have a high number of false positives in our use case."
  },
  {
    "objectID": "posts/methods-sfr/index.html#clustering-knn-or-ann",
    "href": "posts/methods-sfr/index.html#clustering-knn-or-ann",
    "title": "Discussion on Methods to Identify Institutional Investors from Messy Data",
    "section": "Clustering (KNN or ANN)",
    "text": "Clustering (KNN or ANN)\nClustering requires that the data can be vectorized. We can encode owner names string into vectors using a string embedding model. However, these models are generally intended to encode semantic meaning. They are not useful for identifying strings that look similar.\nAddress keys are also vectorized, but we do not gain anything from using a clustering technique versus a simple aggregation.\nClustering only has potential if we consider other dimensions in the data; for instance, if we wanted to include property characteristics. For instance, the same owner might own many properties in the same geographic area. However, this method may cause false positives.\nClustering is likely not a solution to our problem."
  },
  {
    "objectID": "posts/methods-sfr/index.html#deep-learning",
    "href": "posts/methods-sfr/index.html#deep-learning",
    "title": "Discussion on Methods to Identify Institutional Investors from Messy Data",
    "section": "Deep Learning",
    "text": "Deep Learning\nDeep learning requries a correct, labeled dataset to train on. This takes additional effort to create. Furthermore, there are many instances of subsidary corporations with no discernable pattern (see more in next section).\nDeep learning is also likely not a solution."
  }
]